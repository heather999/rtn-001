\section{Data Preview 0}\label{sec:dp0}

In \citeds{LSO-011} we outlined a number of scenarios for early releases of Rubin Observatory~data. The purpose of the these releases are not only to prepare the community for LSST data, but also to serve as an early integration test of existing elements of the Data Management systems and to familiarize the community with our access mechanisms.

Two major new developments have occurred since \citeds{LSO-011} was drafted:

\begin{itemize}

\item There have since been delays in construction such that we are now planning on making Data Previews with Rubin Observatory simulated data or on-sky data from other observatories (see \secref{sec:dataset}) which would still allow us to meet some of the goals of the early releases.

\item We are planning on carrying these activities at the Interim Data Facility, which is is dedicated to Pre-Ops activities infrastructure needs such as serving data and training operations staff. (Commissioning actives will continue at NCSA and in Chile.)

\end{itemize}

In this document we outline notable elements of DP0, the first of these planned data previews, from the Data Management and Pre-Operations perspective.

Data Preview 0 itself is broken down in several parts: 0.1 servings existing data products, 0.2 reprocessing that data and publishing new catalogs.

\subsection{Elements of Data Preview 0.1}

% PJM: Is this section only about DP0.1, serving catalog data from pre-processed images? I think we need to explain the different phases of DP0 at the start, when we show the milestones. And then conisder the dataset options in that context, eg it could be a different mix of data in DP0.1 from DP0.2. Note that a DP0.3 is also possible, given the time available in FY22.

In this section we discuss the following key topics:

\begin{itemize}

\item Dataset choice considerations

\item Data products offered

\item Services offered

\item Audience considerations

\end{itemize}

\subsubsection {Dataset choice considerations} \label{sec:dataset}

The Construction Project has been working for some time now with a number of pre-cursor datasets and simulated data. There are two leading candidates for forming the basis of DP0:

\begin{itemize}

\item The Subaru Hyper Suprime-Cam PDR2 dataset, provided permission can be secured from our HSC colleagues. As real (on-sky) data it is likely that users will interact with it in more realistic ways. It is a well understood dataset, and it is regularly re-processed with software that shares a common codebase with the LSST Science Pipelines.

\item The simulated precursor to LSST data produced by the Dark Energy Science Collaboration, DESC DC2, provided permission can be secured. This is a very large dataset and putting DC2 catalogs in Qserv would be an excellent demonstration of its abilities.

\end{itemize}

There is interest from the science collaborations in working with data products from both of these datasets. DC2 was emphasized at the 2019 PCW, and at least one (AGN) has contributed to the simulation inputs since then. A comment at the PCW discussion was that without DC2 in DP0, the science collaborations would not see full frame LSST data until the year before the survey, too late for the needed analysis development.
% PJM: to re-live the PCW2019 session, see the slide deck at https://docs.google.com/presentation/d/1tRHdSyXBRp850zfJO5NssHS-fGfGMMngDEfAD9Azdk4/edit#slide=id.g5e4570c6eb_0_10 and the notes at https://docs.google.com/document/d/1fSNwsT12hTQGZsH--C6sIY58k6ODHx4vnsPfQa82t9Q/edit#heading=h.8o7p552v6klp

Data Management is currently in transition between its 2nd and 3rd generation data abstraction layer (aka ``Butler''). For DP0 to fulfill its aim as an early deployment/integration exercise, Gen 3 Butler must be used, preferably (stretch goal) using an S3 compliant Object Store as is the intent in production. This has bearing on the choice of dataset.

HSC PDR2 can either be converted from Gen 2 to Gen 3 or (stretch goal but ideally) reprocessed naively with Gen3. A smaller subset may be necessary to avoid production scaling issues. This is the preferred choice in the short term from an engineering point of view.

DC2 is available through Gen2 Butler and as we do not process that data with the Science Pipelines, the only option is conversion to Gen3. Estimates are that this is such a time-consuming process that it cannot be done in time to meet milestone DP-SR-M02. Therefore if DC2 is to be involved in the short term, a significantly smaller subset would have to be selected.

Questions:

\begin{itemize}

\item Which dataset has the broader scientific interest? This question could be answered via a community survey: indeed, the possibility of such a survey was discussed at the 2019 PCW.

\item For either dataset if we take a subset to avoid the Gen2-Gen3 conversion issues or production scaling issues, will that reduce the usefulness of the datasets or affect the choice? What would be the smallest data size that is still scientifically interesting?

\item Are there HiPS maps available for either of these ?

%butler moved to risks

\item Given the delayed construction/commissioning schedule, could we consider including both of these datasets in DP0 over the course of FY21--FY22?

\end{itemize}

\subsubsection{Data Products Offered}

We will offer access to images and catalogs, though in more limited ways that will be available in Operations.
Images will be stored in read-only Butler Gen3 repo.
Catalogs will be stored in Qserv.

We may provide images and catalogs from different production runs based on the same dataset.
For example, in the stretch goal of reprocessing the dataset in Gen 3, catalogs may not be available for Qserv to start ingesting in time. In such a scenario, we may choose to provide existing catalogs from the old run.

The exact science data products depend on what exist in the provided data repository (if serving existing data products) or what pipelines are ready for our reprocessing.

Questions:

\begin{itemize}

\item Are we offering parquet files? --- No promise. Currently our SDMified parquet-generating pipelines are HSC only and Gen2 only. If parquet files are offered the access will be via the read-only Butler Gen3 repo.

\item We should presumably explicitly rule out bulk download  --- YES. However, this ({\it was} discussed at the 2019 PCW, as a potential mitigation against there not being batch compute available in DP0. If a particular group requested bulk download, it could be an opportunity to start developing that capability. We will also need to know whether to allow DESC bulk download access as part of the MOU to gain access to DC2: they may well want to download all the re-processed products, for their own purposes (and to develop their capability to ingest and work with bulk downloads).

\item When does ingest into Qserv has to start to be ready by DP0?

\end{itemize}

\subsubsection{Services Offered}

Although DP0 as a milestone described \citeds{LSO-011} can be fulfilled with simple data distribution, we intend to offer limited Science Platform functionality as part of DP0. This includes:

\begin{itemize}

\item Provided the data is stored in Qserv or a Postgres database, catalogue access through TAP

\item Access to the Science Platform's notebook-based analysis environment (Nublado); images can be accessed pragmatically via the Butler.

\item Catalogue access only (no VO image services) via the Portal

\item Authentication via Github (new self-service Identity Management system offering Federated Authentication will be offered subsequently to DP 0.1)

\end{itemize}

Shell access (except through Nublado) will not be offered.

The science platform will be reachable as data.lsst.cloud ("data" is specified by the Product Owner, "lsst" represents the eventual access to the Legacy Survey of Space and Time, and ".cloud" represents the GCP-deployed IDF, allowing us to bring up the USDF in parallel under a different TLD such as data.lsst.us.

\subsubsection{Audience Considerations}

Care should be taken to limit the target audience for the data previews; it is most critical that this is done for DP0.

\begin{itemize}

\item We have limited capacity to divert resources to support users.

\item We will not have performed scaling tests on the Science Platform services by that point; current Science Platform usage is under 100 users, and any intent to exceed that should be communicated well in advance

\item We will not yet have the ability to throttle excessive IDF usage

\end{itemize}

Authorization will be provided in an all-in basis (users will have the same level of access as project members currently have) since finer access control mechanisms will not be available by DP0; care should be taken in selecting them.

Questions:

\begin{itemize}

\item What is the authorization constraints for this data? For example, are DC2 data products only available to DESC science collaboration members? If so, if DC2 is chosen, does only DESC participate in DP0?
	{\bf No: When agreed, DC2 would be available to all data rights holders.}

\item How do we handle access? First come first served? Do we need a sign-up process?

%support moved to SP section
\end{itemize}

\subsection{DP0.2 - processing}

The Milestone DP-SR-M03 includes re processing on IDF of the data set previously served as part of DP-SR-M01.
This requires a workflow system and associated tools to preferable make this quite automated.
Demonstrating a portable set of cloud enabled tools based on Butler Gen 3 and HTCondor would help to allay the main risk of moving to a new Data Facility in operations.
As of today, processing based on Butler Gen3 has been limited to a very small scale, and no scalability testing has been performed. For DP-SR-M03 we may reprocess only a subset of the dataset constrained by scaling issues.


\subsection{Risks and mitigation}

The biggest schedule risk is not getting an interim data facility in place in time.
This would delay the entire schedule and there is not much mitigation.

In the long run costs may be higher than expected in a cloud based IDF. This will be due to storage.
An mitigation to this would be to store data on our own systems (NCSA or Chile) and expose it through S3.
NCSA already have this in place and we should consider testing this for lesser used data sets.

There is some risk that  Butler over S3 and Postgres  might not be at  production grade by DP0. We are working hard on that in construction. There is the possibility to run Gen 3 over a filesystem which would not be ideal on the cloud. If Gen3 does not work at all we will have to have a major rethink and build a much simpler butler.
Similarly, the workflow system and associated tools may not be mature enough for large-scale production. Scalability in production is also not understood. We may need to limit the size of DP0 and rethink the system.
